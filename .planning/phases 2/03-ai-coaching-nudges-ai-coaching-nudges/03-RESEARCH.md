# Phase 3: AI Coaching Nudges - Research

**Researched:** 2026-02-07
**Domain:** AI text generation (Gemini 2.5 Flash), text-to-speech (ElevenLabs Flash v2.5), browser audio playback, audio pre-caching, SpeechSynthesis fallback, nudge timing/escalation logic
**Confidence:** HIGH

## Summary

Phase 3 builds AI coaching nudges on top of the existing focus scoring pipeline from Phase 2. The codebase already has a working `useAICoaching` hook with ElevenLabs integration, escalation logic, cooldown enforcement, and SpeechSynthesis fallback. The existing `/api/elevenlabs/speak` route works but uses the outdated `eleven_monolingual_v1` model instead of the required `eleven_flash_v2_5`. The current coaching messages are hardcoded strings rather than being generated by Gemini AI.

Phase 3 must accomplish three main things: (1) add Gemini 2.5 Flash API integration to generate contextual coaching text dynamically, (2) upgrade the ElevenLabs route to use Flash v2.5 with proper voice settings, and (3) implement the pre-caching system for 20-30 common nudge audio clips, along with missing timing constraints (60-second session start grace period, no-nudge-during-recovery logic). The existing hook architecture is sound and should be evolved, not rewritten.

**Primary recommendation:** Extend the existing `useAICoaching` hook and `/api/elevenlabs/speak` route. Add a new `/api/coaching/generate` route for Gemini text generation and a new `/api/coaching/precache` route (or build-time script) for pre-generating common audio clips. Store pre-cached audio as static files or in a server-side Map cache.

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| `@google/genai` | ^1.40.0 | Gemini 2.5 Flash text generation for coaching messages | Official Google Gen AI SDK for JS/TS; supports `generateContent` with system instructions |
| ElevenLabs REST API | v1 | Text-to-speech via `eleven_flash_v2_5` model | Already integrated; ~75ms latency, 32 languages, cost-effective |
| Web SpeechSynthesis API | Browser built-in | Fallback TTS when ElevenLabs unavailable | Already implemented in existing hook; offline-capable, zero cost |
| Web Audio API | Browser built-in | Chime sounds (already used) and audio playback management | Already in use via `useFocusChime`; no additional dependency needed |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| Next.js API Routes | 15.5.12 | Server-side API proxy for Gemini and ElevenLabs (keeps API keys secure) | All external API calls must go through server routes |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| `@google/genai` | Direct REST API calls to Gemini | SDK provides typed responses, auto-retry, simpler auth; direct REST adds boilerplate |
| In-memory Map cache for audio | IndexedDB on client | Server-side Map is simpler, serves all clients, avoids client storage limits; IndexedDB adds complexity |
| Pre-cached static audio files | Runtime-only TTS generation | Pre-caching eliminates latency for common phrases; runtime-only risks exceeding 2s target |

**Installation:**
```bash
npm install @google/genai
```

## Architecture Patterns

### Recommended Project Structure
```
src/
├── app/
│   └── api/
│       ├── elevenlabs/
│       │   └── speak/
│       │       └── route.ts          # EXISTING - upgrade model to eleven_flash_v2_5
│       └── coaching/
│           └── generate/
│               └── route.ts          # NEW - Gemini text generation endpoint
├── components/
│   └── coaching/
│       └── NudgeIndicator.tsx        # NEW - visual indicator during voice playback
├── hooks/
│   └── useAICoaching.ts             # EXISTING - extend with Gemini, timing, recovery
└── lib/
    ├── coaching-engine.ts            # NEW - nudge trigger logic, escalation state machine
    ├── coaching-cache.ts             # NEW - pre-cached audio management
    └── coaching-prompts.ts           # NEW - Gemini prompt templates by escalation tier
```

### Pattern 1: Server-Side Audio Cache (Map-Based)
**What:** A module-level `Map<string, Buffer>` in the Next.js API route that caches ElevenLabs audio responses keyed by the exact text string. Because Next.js API routes share module scope across requests (in the same server process), this cache persists between requests without external storage.
**When to use:** For the 20-30 pre-cached common nudge phrases and any dynamically generated phrases seen more than once.
**Example:**
```typescript
// src/lib/coaching-cache.ts
// Source: Application-level pattern for Next.js server-side caching

const audioCache = new Map<string, Buffer>();

export function getCachedAudio(text: string): Buffer | null {
  return audioCache.get(text) ?? null;
}

export function setCachedAudio(text: string, audio: Buffer): void {
  audioCache.set(text, audio);
}

export function isCached(text: string): boolean {
  return audioCache.has(text);
}

export function getCacheSize(): number {
  return audioCache.size;
}
```

### Pattern 2: Gemini System Instruction for Short Coaching Text
**What:** Use Gemini 2.5 Flash with a tightly constrained system instruction to generate 4-8 word coaching nudges. The system instruction defines the persona, tone (based on escalation tier), and strict length constraints.
**When to use:** Every nudge trigger, unless using a pre-cached phrase.
**Example:**
```typescript
// src/lib/coaching-prompts.ts
// Source: @google/genai SDK docs (https://ai.google.dev/gemini-api/docs/text-generation)

import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });

const SYSTEM_INSTRUCTIONS = {
  gentle: `You are a supportive focus coach. Generate a single gentle reminder
to refocus. MUST be 4-8 words. Examples: "Hey, let's get back on track."
"Time to refocus on your work." Never use harsh language.`,

  medium: `You are a firm but caring focus coach. Generate a single nudge to
regain focus. MUST be 4-8 words. Be direct but not harsh. Examples:
"Your focus is slipping, come back." "Let's bring that attention back now."`,

  direct: `You are a no-nonsense focus coach. Generate a single direct command
to focus immediately. MUST be 4-8 words. Be assertive. Examples:
"Stop. Focus. Now." "Enough distractions, get to work."`,
};

export type EscalationTier = "gentle" | "medium" | "direct";

export async function generateCoachingText(
  tier: EscalationTier,
  context?: { sessionMinutes?: number; distractionCount?: number }
): Promise<string> {
  const contextStr = context
    ? `User has been in session for ${context.sessionMinutes ?? 0} minutes with ${context.distractionCount ?? 0} distractions.`
    : "";

  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash",
    contents: `Generate a focus coaching nudge. ${contextStr}`,
    config: {
      systemInstruction: SYSTEM_INSTRUCTIONS[tier],
      temperature: 0.8,  // Some variety in responses
    },
  });

  return response.text?.trim() ?? "Stay focused.";
}
```

### Pattern 3: Nudge State Machine
**What:** A state machine that manages nudge timing constraints: 60-second grace period at session start, 30-second cooldown between nudges, no nudge during active recovery, and escalation tier tracking.
**When to use:** The coaching engine hook checks this state machine before every potential nudge trigger.
**Example:**
```typescript
// src/lib/coaching-engine.ts

export interface NudgeState {
  sessionStartTime: number;
  lastNudgeTime: number;
  escalationLevel: number; // 0=gentle, 1=medium, 2=direct
  isRecovering: boolean;
  consecutiveDistractions: number;
}

export function canTriggerNudge(
  state: NudgeState,
  currentScore: number,
  previousScore: number,
  now: number = Date.now()
): { allowed: boolean; reason?: string } {
  // Rule 1: No nudge in first 60 seconds
  const sessionAge = (now - state.sessionStartTime) / 1000;
  if (sessionAge < 60) {
    return { allowed: false, reason: "grace-period" };
  }

  // Rule 2: 30-second cooldown
  const sinceLast = (now - state.lastNudgeTime) / 1000;
  if (sinceLast < 30) {
    return { allowed: false, reason: "cooldown" };
  }

  // Rule 3: No nudge during active recovery
  if (currentScore > previousScore && state.isRecovering) {
    return { allowed: false, reason: "recovering" };
  }

  return { allowed: true };
}

export function getEscalationTier(level: number): "gentle" | "medium" | "direct" {
  if (level === 0) return "gentle";
  if (level === 1) return "medium";
  return "direct";
}
```

### Pattern 4: Pre-Cache Warm-Up on Session Start
**What:** When a user starts a focus session (clicks "Start"), fire a background API call to pre-generate and cache the 20-30 most common nudge phrases as audio. This happens asynchronously and does not block the session start.
**When to use:** On session initialization, after user interaction (solves autoplay policy).
**Example:**
```typescript
// Warm-up call from client on session start
async function warmUpAudioCache(): Promise<void> {
  try {
    await fetch("/api/coaching/precache", { method: "POST" });
    console.log("[Coaching] Audio cache warmed up");
  } catch (error) {
    console.warn("[Coaching] Cache warm-up failed, will use live generation");
  }
}
```

### Anti-Patterns to Avoid
- **Calling ElevenLabs on every nudge without caching:** Free tier has 10,000 credits/month (~20 min audio) and 2 concurrent request limit. Burning credits on repeated phrases wastes quota.
- **Generating Gemini text AND ElevenLabs audio sequentially on the hot path:** This adds latency. Generate text first, check cache for matching audio, only call ElevenLabs if cache miss.
- **Resetting escalation on every focus recovery:** The requirement says escalation should persist across consecutive distractions within a session. Only reset when explicitly designed to (e.g., after a sustained focus period).
- **Playing audio without prior user interaction:** Chrome blocks AudioContext creation and Audio.play() before user gesture. The session "Start" button click provides the necessary user interaction, but the AudioContext must be initialized during or after that click.
- **Making Gemini API calls from the client:** API key would be exposed. All Gemini calls must go through a Next.js server-side API route.

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Text-to-speech | Custom audio synthesis | ElevenLabs API (`eleven_flash_v2_5`) + SpeechSynthesis fallback | TTS is a solved, complex problem; ElevenLabs provides 75ms latency natural speech |
| AI text generation | Template-based message selection only | Gemini 2.5 Flash API via `@google/genai` | Requirement COACH-01 mandates Gemini; provides contextual variety beyond templates |
| Audio format handling | Custom audio encoding/decoding | Browser's native `Audio` element + `URL.createObjectURL` | Already working in codebase; handles MP3 decoding natively |
| Cooldown/timing | Manual setTimeout chains | State machine with timestamp comparisons in refs | setTimeout chains drift and are hard to debug; timestamp math is deterministic |

**Key insight:** The existing `useAICoaching` hook already handles 70% of the required functionality (ElevenLabs call, fallback, escalation, cooldown, Audio playback). The work is extending it, not replacing it.

## Common Pitfalls

### Pitfall 1: Chrome Autoplay Policy Blocks Audio
**What goes wrong:** `Audio.play()` or `AudioContext.resume()` throws `NotAllowedError` because no user gesture preceded it.
**Why it happens:** Chrome requires a user interaction (click/tap) before audio can play. If the AudioContext or Audio element is created before the user clicks "Start Session," playback is blocked.
**How to avoid:** The existing `useFocusChime` already handles this by lazy-initializing AudioContext. Ensure the coaching audio follows the same pattern: create Audio elements only after session start (which requires a button click). The existing code already creates `new Audio()` inside `playCoachingNudge()` which is called after user interaction chain.
**Warning signs:** `DOMException: play() failed because the user didn't interact with the document first` in console.

### Pitfall 2: ElevenLabs Quota Exhaustion During Demo
**What goes wrong:** After ~20 minutes of audio generation, the free tier quota (10,000 credits) runs out. All subsequent ElevenLabs calls return 429 errors. If fallback is not robust, nudges stop entirely.
**Why it happens:** Each nudge consumes credits proportional to character count. A 6-word nudge (~30 chars) uses ~15 credits. Without caching, a 30-minute session with nudges every 30 seconds would use ~900 credits.
**How to avoid:** (1) Pre-cache common phrases so most nudges are cache hits with zero API cost. (2) Ensure the SpeechSynthesis fallback path in `useAICoaching` is robust (the existing code has this but sets `isPlaying` to false immediately instead of waiting for `onend`). (3) Track remaining quota and switch to fallback proactively.
**Warning signs:** 429 responses from ElevenLabs API, increasing latency in speech generation.

### Pitfall 3: Gemini + ElevenLabs Sequential Latency Exceeds 2 Seconds
**What goes wrong:** Generating coaching text (Gemini: ~200-500ms) + generating audio (ElevenLabs: ~75-500ms) + network overhead = total latency > 2 seconds, violating COACH-10.
**Why it happens:** Two sequential API calls plus network round trips.
**How to avoid:** (1) For pre-cached phrases, skip both API calls entirely (0ms latency). (2) For dynamic phrases, call Gemini first, then check audio cache before calling ElevenLabs. (3) Use `eleven_flash_v2_5` model (75ms vs 250ms+ for other models). (4) Keep Gemini prompts short to minimize generation time. (5) If latency still exceeds 2s, fall back to pre-cached phrase + SpeechSynthesis for the current nudge.
**Warning signs:** Nudge playback starts more than 2 seconds after distraction threshold is crossed.

### Pitfall 4: Nudge Fires During Score Recovery
**What goes wrong:** User starts recovering focus (score trending up) but a nudge fires because the score is still below the threshold that triggered the distraction detection.
**Why it happens:** The chime system detects recovery via `recoveryAmount` (1 point above lowest), but the coaching system checks `chimeCount >= 5` without checking if the score is currently trending upward.
**How to avoid:** Add a "recovery detection" check: if the current score is higher than the score N frames ago (e.g., 3-5 frames), the user is recovering and nudges should be suppressed. This requires tracking a short score history window in the coaching engine.
**Warning signs:** User hears "stop getting distracted" while actively looking back at the screen.

### Pitfall 5: SpeechSynthesis `onend` Event Not Firing
**What goes wrong:** The `isPlaying` state never resets to `false` after browser speech synthesis completes, blocking subsequent nudges.
**Why it happens:** In the current codebase, `setIsPlaying(false)` is called immediately after `speechSynthesis.speak()` rather than in the `onend` callback. This is a bug in the existing code. Additionally, some browsers/platforms have known issues where `onend` does not fire reliably (especially on mobile or when the tab is backgrounded).
**How to avoid:** Wait for `onend` to fire, but also add a safety timeout (e.g., 10 seconds) that resets `isPlaying` if `onend` never fires.
**Warning signs:** "AI Coach Speaking..." indicator stays visible indefinitely.

## Code Examples

Verified patterns from official sources:

### Gemini 2.5 Flash Text Generation
```typescript
// Source: https://ai.google.dev/gemini-api/docs/text-generation
// Source: https://ai.google.dev/gemini-api/docs/quickstart

import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });

const response = await ai.models.generateContent({
  model: "gemini-2.5-flash",
  contents: "Generate a 4-8 word focus coaching nudge.",
  config: {
    systemInstruction: "You are a focus coach. Keep responses under 8 words.",
    temperature: 0.8,
  },
});

const nudgeText = response.text;
```

### ElevenLabs Flash v2.5 TTS
```typescript
// Source: https://elevenlabs.io/docs/api-reference/text-to-speech
// Model ID: eleven_flash_v2_5 (from https://elevenlabs.io/docs/overview/models)

const voiceId = "21m00Tcm4TlvDq8ikWAM"; // "Rachel" voice

const response = await fetch(
  `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,
  {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "xi-api-key": process.env.ELEVENLABS_API_KEY!,
    },
    body: JSON.stringify({
      text: "Let's refocus on your task.",
      model_id: "eleven_flash_v2_5",  // ~75ms latency, was eleven_monolingual_v1
      voice_settings: {
        stability: 0.5,
        similarity_boost: 0.75,
      },
    }),
  }
);

const audioBuffer = await response.arrayBuffer();
// Returns audio/mpeg content
```

### Browser SpeechSynthesis Fallback with Safety Timeout
```typescript
// Source: https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis

function speakWithFallback(text: string): Promise<void> {
  return new Promise((resolve) => {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = 1.0;
    utterance.pitch = 1.0;
    utterance.volume = 1.0;

    // Safety timeout in case onend never fires
    const safetyTimeout = setTimeout(() => {
      console.warn("[SpeechSynthesis] onend timeout, forcing resolve");
      resolve();
    }, 10_000);

    utterance.onend = () => {
      clearTimeout(safetyTimeout);
      resolve();
    };

    utterance.onerror = () => {
      clearTimeout(safetyTimeout);
      resolve();
    };

    speechSynthesis.speak(utterance);
  });
}
```

### Next.js API Route for Gemini Coaching Generation
```typescript
// src/app/api/coaching/generate/route.ts

import { NextRequest, NextResponse } from "next/server";
import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });

const SYSTEM_PROMPTS: Record<string, string> = {
  gentle: "You are a supportive focus coach. Generate ONE gentle reminder to refocus. 4-8 words max. No quotes.",
  medium: "You are a firm focus coach. Generate ONE direct nudge to regain focus. 4-8 words max. No quotes.",
  direct: "You are a no-nonsense coach. Generate ONE assertive command to focus NOW. 4-8 words max. No quotes.",
};

export async function POST(request: NextRequest) {
  try {
    const { tier = "gentle", context } = await request.json();

    const systemInstruction = SYSTEM_PROMPTS[tier] || SYSTEM_PROMPTS.gentle;

    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: context
        ? `Generate a nudge. Context: ${context}`
        : "Generate a focus coaching nudge.",
      config: {
        systemInstruction,
        temperature: 0.8,
      },
    });

    const text = response.text?.trim() ?? "Stay focused.";
    return NextResponse.json({ text });
  } catch (error) {
    console.error("[Coaching API] Gemini error:", error);
    return NextResponse.json({ text: "Time to refocus." }); // Graceful fallback
  }
}
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| `eleven_monolingual_v1` | `eleven_flash_v2_5` | 2024-2025 | 75ms vs 300ms+ latency; 32 vs 1 language; same credit cost |
| `@google/generative-ai` npm package | `@google/genai` npm package | Late 2025 | New SDK name; uses `ai.models.generateContent()` not `model.generateContent()` |
| Hardcoded coaching messages | Gemini-generated contextual messages | Phase 3 requirement | More variety, context-aware, personalized to session state |

**Deprecated/outdated:**
- `eleven_monolingual_v1`: Still works but significantly slower (~300ms+) than Flash v2.5 (~75ms). The existing codebase uses this and must be upgraded.
- `eleven_turbo_v2`: Mentioned in PROJECT.md but superseded by `eleven_flash_v2_5` which is faster and cheaper.
- `@google/generative-ai`: The old Google AI SDK. The new package is `@google/genai` (v1.40.0+).

## Open Questions

1. **Gemini API Key Configuration**
   - What we know: The project has `ELEVENLABS_API_KEY` in `.env.local`. Gemini API requires `GEMINI_API_KEY` (or `GOOGLE_API_KEY`).
   - What's unclear: Whether the user already has a Gemini API key. The `.env.local` only contains the ElevenLabs key.
   - Recommendation: Add `GEMINI_API_KEY` to `.env.local`. The plan should include a task to set up the env var. Gemini API has a generous free tier through Google AI Studio.

2. **Pre-Cache Corpus: 20-30 Phrases**
   - What we know: Requirement COACH-05 specifies pre-caching 20-30 common nudge audio clips.
   - What's unclear: Whether to generate these at build time, on first session start, or lazily on first use. Build time requires the API key available during build.
   - Recommendation: Generate on first session start via a background `/api/coaching/precache` POST call. Store in server-side Map. This avoids build-time API key requirement and amortizes cost across the first session.

3. **Which ElevenLabs Voice to Use**
   - What we know: Current code uses voice ID `21m00Tcm4TlvDq8ikWAM` ("Rachel"). Plan.md mentions wanting natural, professional audio.
   - What's unclear: Whether Rachel is the best voice for coaching nudges, or if a different voice might feel more authoritative/supportive.
   - Recommendation: Keep Rachel for now (already tested and working). Voice selection is cosmetic and can be changed later without architectural impact.

4. **Escalation Reset Policy**
   - What we know: Existing code resets escalation to gentle when `chimeCount` goes back to 0 (user recovers). Requirement COACH-07 says "escalating nudge intensity across consecutive distraction events within a session."
   - What's unclear: Does "consecutive distraction events" mean escalation should persist across recovery periods, or reset to gentle after each recovery?
   - Recommendation: Escalation should persist within a session (gentle -> medium -> direct) across multiple distraction events. Only full recovery (e.g., sustained high focus for 2+ minutes) should reset to gentle. This matches the "within a session" language.

## Sources

### Primary (HIGH confidence)
- [ElevenLabs Models](https://elevenlabs.io/docs/overview/models) - Flash v2.5 model ID `eleven_flash_v2_5`, ~75ms latency, 32 languages
- [ElevenLabs TTS API](https://elevenlabs.io/docs/api-reference/text-to-speech) - Create speech endpoint, voice settings parameters
- [Google Gemini API Quickstart](https://ai.google.dev/gemini-api/docs/quickstart) - `@google/genai` SDK, `generateContent` API
- [Gemini Text Generation](https://ai.google.dev/gemini-api/docs/text-generation) - System instructions, temperature config
- [@google/genai npm](https://www.npmjs.com/package/@google/genai) - v1.40.0, official SDK
- [MDN SpeechSynthesis](https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis) - Browser TTS API reference
- [Chrome Autoplay Policy](https://developer.chrome.com/blog/autoplay) - User gesture requirements for audio

### Secondary (MEDIUM confidence)
- [ElevenLabs Free Tier Limits](https://help.elevenlabs.io/hc/en-us/articles/14312733311761) - 10,000 credits/month, 2 concurrent requests on free tier
- [ElevenLabs Caching Cookbook](https://elevenlabs.io/docs/cookbooks/text-to-speech/streaming-and-caching-with-supabase) - Hash-based caching pattern (URL was 404 at fetch time, info from search snippets)
- [Can I Use SpeechSynthesis](https://caniuse.com/speech-synthesis) - 75% browser compatibility score

### Tertiary (LOW confidence)
- Gemini model name `gemini-2.5-flash` vs `gemini-3-flash-preview` - Official quickstart docs showed `gemini-3-flash-preview` but the npm page and other sources reference `gemini-2.5-flash`. The project requirements specify Gemini 2.5 Flash. Need to verify the exact model string at implementation time. Using `gemini-2.5-flash` per project requirements.

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - All libraries verified via official docs and npm; existing codebase already uses ElevenLabs and Audio APIs
- Architecture: HIGH - Extending existing patterns (hooks, API routes) rather than introducing new paradigms; pre-caching pattern is straightforward Map-based cache
- Pitfalls: HIGH - Autoplay policy, quota limits, and latency concerns are well-documented and verified across multiple sources; existing codebase bugs (SpeechSynthesis `isPlaying` timing) identified through code review

**Existing code assessment:**
- `useAICoaching.ts` (235 lines): 70% complete for Phase 3. Needs: Gemini integration, 60s grace period, recovery detection, pre-cache awareness
- `/api/elevenlabs/speak/route.ts` (83 lines): Working but needs model upgrade (`eleven_monolingual_v1` -> `eleven_flash_v2_5`)
- `useFocusChime.ts` (177 lines): Provides the `chimeCount` signal that triggers coaching. No changes needed.
- `DetectionProvider.tsx` (162 lines): Already wires up `useAICoaching` and displays the coaching indicator. Needs minor UI updates for the visual nudge indicator (COACH-03, UI-04).

**Research date:** 2026-02-07
**Valid until:** 2026-03-07 (30 days - APIs are stable, SDKs may update)
