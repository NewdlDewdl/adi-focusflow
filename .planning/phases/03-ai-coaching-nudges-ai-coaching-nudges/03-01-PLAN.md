---
phase: 03-ai-coaching-nudges
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/coaching-engine.ts
  - src/lib/coaching-prompts.ts
  - src/lib/coaching-cache.ts
  - src/app/api/coaching/generate/route.ts
  - src/app/api/elevenlabs/speak/route.ts
autonomous: true
user_setup:
  - service: gemini
    why: "AI coaching text generation via Gemini 2.5 Flash"
    env_vars:
      - name: GEMINI_API_KEY
        source: "Google AI Studio (https://aistudio.google.com/apikey) -> Create API key -> Copy"

must_haves:
  truths:
    - "Coaching engine correctly enforces 60-second grace period at session start"
    - "Coaching engine correctly enforces 30-second cooldown between nudges"
    - "Coaching engine suppresses nudges when focus score is actively recovering"
    - "Coaching engine tracks escalation tiers (gentle -> medium -> direct) across distraction events"
    - "Gemini API route returns contextual 4-8 word coaching text by escalation tier"
    - "ElevenLabs route uses eleven_flash_v2_5 model and returns cached audio on repeat requests"
  artifacts:
    - path: "src/lib/coaching-engine.ts"
      provides: "Nudge state machine with canTriggerNudge, getEscalationTier, createNudgeState"
      exports: ["canTriggerNudge", "getEscalationTier", "createNudgeState", "NudgeState"]
    - path: "src/lib/coaching-prompts.ts"
      provides: "Gemini system prompts by tier and generateCoachingText function"
      exports: ["generateCoachingText", "EscalationTier", "COMMON_NUDGE_PHRASES"]
    - path: "src/lib/coaching-cache.ts"
      provides: "Server-side audio cache Map with get/set/has operations"
      exports: ["getCachedAudio", "setCachedAudio", "isCached", "getCacheSize"]
    - path: "src/app/api/coaching/generate/route.ts"
      provides: "POST endpoint for Gemini coaching text generation"
      exports: ["POST"]
    - path: "src/app/api/elevenlabs/speak/route.ts"
      provides: "Upgraded POST endpoint using eleven_flash_v2_5 with server-side caching"
      exports: ["POST"]
  key_links:
    - from: "src/app/api/coaching/generate/route.ts"
      to: "src/lib/coaching-prompts.ts"
      via: "imports generateCoachingText"
      pattern: "import.*generateCoachingText.*coaching-prompts"
    - from: "src/app/api/elevenlabs/speak/route.ts"
      to: "src/lib/coaching-cache.ts"
      via: "imports cache functions for audio dedup"
      pattern: "import.*coaching-cache"
---

<objective>
Create the coaching engine foundation: pure nudge timing/escalation logic, Gemini text generation API route, and upgraded ElevenLabs TTS route with server-side caching.

Purpose: Establishes the three server-side pillars that Plan 02 wires into the client -- (1) when to nudge, (2) what to say, (3) how to speak it. Covers requirements COACH-01, COACH-02, COACH-04, COACH-05 (cache foundation), COACH-07, COACH-08, COACH-09.
Output: Three lib modules (coaching-engine, coaching-prompts, coaching-cache), one new API route (/api/coaching/generate), one upgraded API route (/api/elevenlabs/speak).
</objective>

<execution_context>
@/Users/adiga/.claude/get-shit-done/workflows/execute-plan.md
@/Users/adiga/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-coaching-nudges-ai-coaching-nudges/03-RESEARCH.md
@src/hooks/useAICoaching.ts
@src/app/api/elevenlabs/speak/route.ts
@src/hooks/useFocusChime.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create coaching engine, prompts, and cache modules</name>
  <files>
    src/lib/coaching-engine.ts
    src/lib/coaching-prompts.ts
    src/lib/coaching-cache.ts
  </files>
  <action>
    Install @google/genai: `npm install @google/genai`

    **src/lib/coaching-engine.ts** -- Pure nudge state machine (zero React deps):

    Export `NudgeState` interface:
    - sessionStartTime: number
    - lastNudgeTime: number
    - escalationLevel: number (0=gentle, 1=medium, 2=direct)
    - consecutiveDistractions: number
    - scoreHistory: number[] (last 5 scores for recovery detection)

    Export `createNudgeState(sessionStartTime: number): NudgeState` -- factory with defaults (lastNudgeTime=0, escalationLevel=0, consecutiveDistractions=0, scoreHistory=[]).

    Export `canTriggerNudge(state: NudgeState, currentScore: number, now?: number): { allowed: boolean; reason?: string }`:
    - Rule 1 (COACH-08): `(now - state.sessionStartTime) / 1000 < 60` -> return `{ allowed: false, reason: "grace-period" }`
    - Rule 2 (COACH-04): `(now - state.lastNudgeTime) / 1000 < 30` -> return `{ allowed: false, reason: "cooldown" }`
    - Rule 3 (COACH-09): Check if score is recovering -- if `state.scoreHistory.length >= 3` and the last 3 scores are monotonically increasing (each >= previous), return `{ allowed: false, reason: "recovering" }`. This checks a 3-frame trend, not just 1 frame.
    - Otherwise: `{ allowed: true }`

    Export `getEscalationTier(level: number): "gentle" | "medium" | "direct"` -- 0->gentle, 1->medium, >=2->direct.

    Export `advanceEscalation(state: NudgeState): NudgeState` -- returns new state with escalationLevel = min(state.escalationLevel + 1, 2), consecutiveDistractions + 1.

    Export `updateScoreHistory(state: NudgeState, score: number): NudgeState` -- appends score, keeps last 5 entries.

    Export `shouldResetEscalation(state: NudgeState): boolean` -- returns true if all 5 entries in scoreHistory are >= 70 (sustained high focus = reset to gentle). This implements the "sustained focus for 2+ minutes" reset policy from research.

    **src/lib/coaching-prompts.ts** -- Gemini prompt templates:

    Export `EscalationTier` type: "gentle" | "medium" | "direct".

    Export `SYSTEM_INSTRUCTIONS: Record<EscalationTier, string>` -- exactly as in research (gentle = supportive, medium = firm, direct = assertive). Each instruction constrains output to 4-8 words and includes 2-3 examples.

    Export `COMMON_NUDGE_PHRASES: Record<EscalationTier, string[]>` -- 8-10 phrases per tier (total ~25-30). Pull from the existing COACHING_MESSAGES in useAICoaching.ts plus additional phrases. These are the pre-cache corpus (COACH-05).

    Export `async function generateCoachingText(tier: EscalationTier, context?: { sessionMinutes?: number; distractionCount?: number }): Promise<string>`:
    - Instantiate GoogleGenAI with process.env.GEMINI_API_KEY
    - Call ai.models.generateContent with model "gemini-2.5-flash", contents including context string, config with systemInstruction and temperature 0.8
    - Return trimmed text, fallback to random phrase from COMMON_NUDGE_PHRASES[tier] if API fails
    - This function is server-only (uses process.env)

    **src/lib/coaching-cache.ts** -- Server-side audio cache:

    Module-level `const audioCache = new Map<string, Buffer>()`

    Export `getCachedAudio(text: string): Buffer | null`
    Export `setCachedAudio(text: string, audio: Buffer): void`
    Export `isCached(text: string): boolean`
    Export `getCacheSize(): number`
    Export `getAllCachedTexts(): string[]` -- returns Array.from(audioCache.keys()), useful for debugging

    Keep it simple -- no eviction policy needed for 30 items.
  </action>
  <verify>
    1. `npx tsc --noEmit` passes with no errors
    2. `npm run build` succeeds
    3. Verify coaching-engine.ts exports: canTriggerNudge, getEscalationTier, createNudgeState, advanceEscalation, updateScoreHistory, shouldResetEscalation
    4. Verify coaching-prompts.ts has COMMON_NUDGE_PHRASES with ~25-30 total phrases across 3 tiers
    5. Verify coaching-cache.ts exports cache CRUD operations
  </verify>
  <done>
    Three pure modules exist with zero React dependencies. coaching-engine enforces all 3 timing rules (60s grace, 30s cooldown, recovery suppression). coaching-prompts has Gemini generation function and 25-30 pre-cache phrases. coaching-cache provides Map-based audio storage.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Gemini API route and upgrade ElevenLabs route with caching</name>
  <files>
    src/app/api/coaching/generate/route.ts
    src/app/api/elevenlabs/speak/route.ts
  </files>
  <action>
    **src/app/api/coaching/generate/route.ts** -- NEW Gemini endpoint:

    POST handler accepting JSON body: `{ tier?: "gentle" | "medium" | "direct", context?: string }`
    - Default tier to "gentle" if not provided
    - Import and call `generateCoachingText(tier, contextObj)` from coaching-prompts.ts
    - Return `NextResponse.json({ text })` on success
    - On error (missing API key, Gemini failure), return a random phrase from COMMON_NUDGE_PHRASES[tier] as graceful fallback -- never return an error to client, always return usable text
    - Log errors server-side with `[Coaching API]` prefix

    **src/app/api/elevenlabs/speak/route.ts** -- UPGRADE existing route:

    1. Change model_id from "eleven_monolingual_v1" to "eleven_flash_v2_5" (COACH-02, COACH-10 latency)
    2. Import { getCachedAudio, setCachedAudio, isCached } from "@/lib/coaching-cache"
    3. Before calling ElevenLabs API, check `isCached(text)`:
       - If cached: return cached Buffer directly as audio/mpeg response, log "[ElevenLabs API] Cache hit"
       - If not cached: call ElevenLabs API as before, then `setCachedAudio(text, Buffer.from(audioBuffer))` before returning
    4. Add `accept` query param support: POST body can include `{ text, cache?: boolean }` -- if `cache` is true, prioritize caching (for pre-cache route to use)
    5. Keep existing error handling and logging

    Create precache endpoint:
    **src/app/api/coaching/precache/route.ts** -- NEW pre-cache warm-up:

    POST handler (no body needed):
    - Import COMMON_NUDGE_PHRASES from coaching-prompts.ts
    - Import { isCached } from coaching-cache.ts
    - Iterate all phrases across all tiers
    - For each phrase NOT already cached, call the internal ElevenLabs speak route via fetch("http://localhost:${PORT}/api/elevenlabs/speak") -- actually, to avoid the self-fetch complexity, directly call the ElevenLabs API inline (reuse the same fetch logic) and store in cache
    - Process in batches of 2 (ElevenLabs free tier allows 2 concurrent requests)
    - Return JSON with { cached: number, total: number, skipped: number }
    - Wrap entire operation in try/catch, return partial success on failure
    - Log progress: "[Precache] Caching phrase N/M..."

    NOTE: The precache route should directly call the ElevenLabs API and cache the results, not call the /api/elevenlabs/speak route (avoids self-request issues in Next.js).
  </action>
  <verify>
    1. `npx tsc --noEmit` passes
    2. `npm run build` succeeds
    3. Verify /api/coaching/generate/route.ts exports POST
    4. Verify /api/elevenlabs/speak/route.ts contains "eleven_flash_v2_5" (not "eleven_monolingual_v1")
    5. Verify /api/elevenlabs/speak/route.ts imports from coaching-cache
    6. Verify /api/coaching/precache/route.ts exports POST and imports COMMON_NUDGE_PHRASES
  </verify>
  <done>
    Three API routes functional: /api/coaching/generate returns AI-generated coaching text with graceful fallback, /api/elevenlabs/speak uses Flash v2.5 model with server-side caching, /api/coaching/precache warms the audio cache with all common phrases. All routes build successfully.
  </done>
</task>

</tasks>

<verification>
1. `npm run build` completes with no errors
2. All three lib modules (coaching-engine, coaching-prompts, coaching-cache) have correct exports
3. coaching-engine.ts canTriggerNudge enforces: grace period (60s), cooldown (30s), recovery suppression (3-frame trend)
4. ElevenLabs route uses "eleven_flash_v2_5" model
5. Gemini route gracefully falls back to hardcoded phrases when API key missing
6. Pre-cache route processes all COMMON_NUDGE_PHRASES
</verification>

<success_criteria>
- Build passes with zero errors
- 3 new lib modules, 2 new API routes, 1 upgraded API route
- Pure coaching engine logic is testable without React or network dependencies
- Server-side audio cache is shared across requests via module-level Map
- Gemini integration uses @google/genai SDK with system instructions per escalation tier
- ElevenLabs model upgraded from eleven_monolingual_v1 to eleven_flash_v2_5
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-coaching-nudges-ai-coaching-nudges/03-01-SUMMARY.md`
</output>
